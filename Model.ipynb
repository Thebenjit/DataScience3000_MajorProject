{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7260597-c012-4ba0-b190-11b669b13d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>smokes</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diet drinks drugs smokes  status\n",
       "0    5      2     0      3     0.0\n",
       "1    6      3     1      0     0.0\n",
       "2    5      2    -1      0     0.0\n",
       "3    1      2    -1      0     0.0\n",
       "4   -1      2     0      0     0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'OKCupid_profiles.csv' \n",
    "okcupid_data = pd.read_csv(file_path)\n",
    "\n",
    "# Select relevant columns\n",
    "relevant_columns = ['diet', 'drinks', 'drugs', 'smokes', 'status']\n",
    "okcupid_data_subset = okcupid_data[relevant_columns].copy()  \n",
    "\n",
    "# Map `status` to binary categories: `single` -> 0, `in a relationship` -> 1\n",
    "status_mapping = {\n",
    "    'single': 0,\n",
    "    'available': 0,  # Assuming \"available\" also means single\n",
    "    'seeing someone': 1,\n",
    "    'married': 1,\n",
    "    'unknown': None  # Treating \"unknown\" as missing\n",
    "}\n",
    "okcupid_data_subset['status'] = okcupid_data_subset['status'].map(status_mapping)\n",
    "\n",
    "# Fill missing values in lifestyle habit columns with \"unknown\"\n",
    "okcupid_data_subset.fillna({'diet': 'unknown', 'drinks': 'unknown', \n",
    "                            'drugs': 'unknown', 'smokes': 'unknown'}, inplace=True)\n",
    "\n",
    "# Encode `drinks`\n",
    "drinks_mapping = {\n",
    "    'not at all': 0,\n",
    "    'rarely': 1,\n",
    "    'socially': 2,\n",
    "    'often': 3,\n",
    "    'very often': 4,\n",
    "    'desperately': 5,\n",
    "    'unknown': -1\n",
    "}\n",
    "okcupid_data_subset.loc[:, 'drinks'] = okcupid_data_subset['drinks'].map(drinks_mapping)\n",
    "\n",
    "# Encode `drugs`\n",
    "drugs_mapping = {\n",
    "    'never': 0,\n",
    "    'sometimes': 1,\n",
    "    'often': 2,\n",
    "    'unknown': -1\n",
    "}\n",
    "okcupid_data_subset.loc[:, 'drugs'] = okcupid_data_subset['drugs'].map(drugs_mapping)\n",
    "\n",
    "# Encode `smokes`\n",
    "smokes_mapping = {\n",
    "    'no': 0,\n",
    "    'trying to quit': 1,\n",
    "    'when drinking': 2,\n",
    "    'sometimes': 3,\n",
    "    'yes': 4,\n",
    "    'unknown': -1\n",
    "}\n",
    "okcupid_data_subset.loc[:, 'smokes'] = okcupid_data_subset['smokes'].map(smokes_mapping)\n",
    "\n",
    "# Simplify and encode `diet`\n",
    "diet_categories = {\n",
    "    'vegetarian': 1, 'vegan': 2, 'kosher': 3, 'halal': 4, 'anything': 5,\n",
    "    'other': 6, 'unknown': -1\n",
    "}\n",
    "okcupid_data_subset.loc[:, 'diet'] = okcupid_data_subset['diet'].apply(\n",
    "    lambda x: diet_categories.get(next((key for key in diet_categories if key in str(x)), 'unknown'))\n",
    ")\n",
    "\n",
    "# Split data into features and target\n",
    "X = okcupid_data_subset[['diet', 'drinks', 'drugs', 'smokes']]\n",
    "y = okcupid_data_subset['status']\n",
    "\n",
    "# Handle missing target values\n",
    "X = X[y.notnull()]\n",
    "y = y[y.notnull()]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "okcupid_data_subset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88011301-5da5-44d5-88cb-95748baa6ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.61      0.75     11513\n",
      "         1.0       0.06      0.55      0.10       475\n",
      "\n",
      "    accuracy                           0.61     11988\n",
      "   macro avg       0.51      0.58      0.42     11988\n",
      "weighted avg       0.93      0.61      0.72     11988\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.6124556679634463\n"
     ]
    }
   ],
   "source": [
    "# Works only a little bit --------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train Random Forest model with class weights to handle imbalance\n",
    "rf_model_balanced = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
    "rf_model_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred_balanced = rf_model_balanced.predict(X_test)\n",
    "y_proba_balanced = rf_model_balanced.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Generate classification report and ROC-AUC score\n",
    "classification_report_result_balanced = classification_report(y_test, y_pred_balanced)\n",
    "roc_auc_balanced = roc_auc_score(y_test, y_proba_balanced)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report_result_balanced)\n",
    "print(\"\\nROC-AUC Score:\", roc_auc_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc0b8193-250e-4ceb-93c8-64195aaded06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation mean accuracy: 0.9604\n",
      "Cross-validation accuracy standard deviation: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the pipeline for modeling\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "    ('scaler', StandardScaler()),                # Standardize the data\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))  # Logistic regression\n",
    "])\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Calculate mean and standard deviation of cross-validation scores\n",
    "cv_mean = np.mean(cv_scores)\n",
    "cv_std = np.std(cv_scores)\n",
    "\n",
    "# Print results\n",
    "print(f\"Cross-validation mean accuracy: {cv_mean:.4f}\")\n",
    "print(f\"Cross-validation accuracy standard deviation: {cv_std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21b55327-7165-48ef-a271-f9c0d36cfa59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "0.0    96.039108\n",
       "1.0     3.960892\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate class distribution in the target variable\n",
    "class_distribution = y.value_counts(normalize=True) * 100  # Percentage distribution\n",
    "\n",
    "# Display class distribution\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b8a0cda-6dfc-4244-9a21-ee3df266c308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0529\n",
      "Recall: 0.6232\n",
      "F1 Score: 0.0975\n",
      "ROC-AUC: 0.6012\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Fit the pipeline on the resampled training data\n",
    "pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC\n",
    "\n",
    "# Evaluate the model using precision, recall, F1-score, and ROC-AUC\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92efc338-6d6a-4fd4-8f11-155aabd98231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Precision: 0.0541\n",
      "Random Forest Recall: 0.5516\n",
      "Random Forest F1 Score: 0.0986\n",
      "Random Forest ROC-AUC: 0.5928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Define the Random Forest model\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# Fit the model on the oversampled training data\n",
    "random_forest.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_proba_rf = random_forest.predict_proba(X_test)[:, 1]  # Probabilities for ROC-AUC\n",
    "\n",
    "# Evaluate the model using precision, recall, F1-score, and ROC-AUC\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Random Forest Precision: {precision_rf:.4f}\")\n",
    "print(f\"Random Forest Recall: {recall_rf:.4f}\")\n",
    "print(f\"Random Forest F1 Score: {f1_rf:.4f}\")\n",
    "print(f\"Random Forest ROC-AUC: {roc_auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ce45766-77d3-4960-9c6a-a0bb1a038425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best Parameters: {'class_weight': 'balanced', 'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Precision: 0.0543\n",
      "Recall: 0.5537\n",
      "F1 Score: 0.0989\n",
      "ROC-AUC: 0.5946\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Reapply SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define a parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "    'class_weight': ['balanced']      # Handle class imbalance\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='f1',  # Optimize for F1 score to balance precision and recall\n",
    "    n_jobs=-1,  # Use all available processors\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the grid search to the oversampled training data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "y_pred_proba_best = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics for the best model\n",
    "precision_best = precision_score(y_test, y_pred_best)\n",
    "recall_best = recall_score(y_test, y_pred_best)\n",
    "f1_best = f1_score(y_test, y_pred_best)\n",
    "roc_auc_best = roc_auc_score(y_test, y_pred_proba_best)\n",
    "\n",
    "print(f\"Precision: {precision_best:.4f}\")\n",
    "print(f\"Recall: {recall_best:.4f}\")\n",
    "print(f\"F1 Score: {f1_best:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc_best:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cebf2d85-8f28-4ef3-b14f-122d2b0da10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended Features Precision: 0.0543\n",
      "Extended Features Recall: 0.5537\n",
      "Extended Features F1 Score: 0.0990\n",
      "Extended Features ROC-AUC: 0.5942\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Add lifestyle score and interaction terms before resampling\n",
    "weights = {\n",
    "    'diet': 1.0,\n",
    "    'drinks': 1.5,\n",
    "    'drugs': 1.2,\n",
    "    'smokes': 1.3\n",
    "}\n",
    "\n",
    "X_train['lifestyle_score'] = (\n",
    "    weights['diet'] * X_train['diet'] +\n",
    "    weights['drinks'] * X_train['drinks'] +\n",
    "    weights['drugs'] * X_train['drugs'] +\n",
    "    weights['smokes'] * X_train['smokes']\n",
    ")\n",
    "\n",
    "X_train['diet_drinks'] = X_train['diet'] * X_train['drinks']\n",
    "X_train['diet_drugs'] = X_train['diet'] * X_train['drugs']\n",
    "X_train['drinks_drugs'] = X_train['drinks'] * X_train['drugs']\n",
    "X_train['smokes_drinks'] = X_train['smokes'] * X_train['drinks']\n",
    "\n",
    "# Add the same features for the test set\n",
    "X_test['lifestyle_score'] = (\n",
    "    weights['diet'] * X_test['diet'] +\n",
    "    weights['drinks'] * X_test['drinks'] +\n",
    "    weights['drugs'] * X_test['drugs'] +\n",
    "    weights['smokes'] * X_test['smokes']\n",
    ")\n",
    "\n",
    "X_test['diet_drinks'] = X_test['diet'] * X_test['drinks']\n",
    "X_test['diet_drugs'] = X_test['diet'] * X_test['drugs']\n",
    "X_test['drinks_drugs'] = X_test['drinks'] * X_test['drugs']\n",
    "X_test['smokes_drinks'] = X_test['smokes'] * X_test['drinks']\n",
    "\n",
    "# Select the updated feature set\n",
    "features = ['diet', 'drinks', 'drugs', 'smokes', 'lifestyle_score',\n",
    "            'diet_drinks', 'diet_drugs', 'drinks_drugs', 'smokes_drinks']\n",
    "X_train_extended = X_train[features]\n",
    "\n",
    "# Apply SMOTE on the extended feature set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_extended, y_train)\n",
    "\n",
    "# Train the Random Forest model\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "X_test_extended = X_test[features]\n",
    "y_pred_extended = best_model.predict(X_test_extended)\n",
    "y_pred_proba_extended = best_model.predict_proba(X_test_extended)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "precision_extended = precision_score(y_test, y_pred_extended)\n",
    "recall_extended = recall_score(y_test, y_pred_extended)\n",
    "f1_extended = f1_score(y_test, y_pred_extended)\n",
    "roc_auc_extended = roc_auc_score(y_test, y_pred_proba_extended)\n",
    "\n",
    "# Print results\n",
    "print(f\"Extended Features Precision: {precision_extended:.4f}\")\n",
    "print(f\"Extended Features Recall: {recall_extended:.4f}\")\n",
    "print(f\"Extended Features F1 Score: {f1_extended:.4f}\")\n",
    "print(f\"Extended Features ROC-AUC: {roc_auc_extended:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "745968f1-dd81-476d-926c-3eb3effa9a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: Counter({0.0: 46049, 1.0: 46049})\n",
      "Balanced Features Precision: 0.0543\n",
      "Balanced Features Recall: 0.5537\n",
      "Balanced Features F1 Score: 0.0990\n",
      "Balanced Features ROC-AUC: 0.5942\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to create a balanced dataset\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)  # 'auto' balances the dataset\n",
    "X_balanced, y_balanced = smote.fit_resample(X_train_extended, y_train)\n",
    "\n",
    "# Check the class distribution after balancing\n",
    "from collections import Counter\n",
    "print(f\"Class distribution after SMOTE: {Counter(y_balanced)}\")\n",
    "\n",
    "# Train the Random Forest model on the balanced dataset\n",
    "best_model.fit(X_balanced, y_balanced)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_balanced = best_model.predict(X_test_extended)\n",
    "y_pred_proba_balanced = best_model.predict_proba(X_test_extended)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "precision_balanced = precision_score(y_test, y_pred_balanced)\n",
    "recall_balanced = recall_score(y_test, y_pred_balanced)\n",
    "f1_balanced = f1_score(y_test, y_pred_balanced)\n",
    "roc_auc_balanced = roc_auc_score(y_test, y_pred_proba_balanced)\n",
    "\n",
    "# Print results\n",
    "print(f\"Balanced Features Precision: {precision_balanced:.4f}\")\n",
    "print(f\"Balanced Features Recall: {recall_balanced:.4f}\")\n",
    "print(f\"Balanced Features F1 Score: {f1_balanced:.4f}\")\n",
    "print(f\"Balanced Features ROC-AUC: {roc_auc_balanced:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef8fe80-2a97-4814-a35e-ecd0eaeb9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
